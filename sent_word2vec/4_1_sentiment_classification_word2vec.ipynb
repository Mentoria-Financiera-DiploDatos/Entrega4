{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.1 - Sent text classification using word2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Mh6KU_JkYi"
      },
      "source": [
        "##4.1 - Sentiment text classification using Gensim Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpy1_QfbVf8C"
      },
      "source": [
        "import pandas as pd\n",
        "import gensim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "B6uLb5KMRW7P",
        "outputId": "1faa7cac-304d-42f8-e108-869aabe85963"
      },
      "source": [
        "df_sent = pd.read_csv(\"https://raw.githubusercontent.com/Mentoria-Financiera-DiploDatos/Entrega3/master/sentimientos/data/feeling_procesado.csv\")\n",
        "print(df_sent.news.size)\n",
        "df_sent.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>feeling</th>\n",
              "      <th>news</th>\n",
              "      <th>news_tokens</th>\n",
              "      <th>news_tokens_tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>['accord', 'gran', 'company', 'plan', 'move', ...</td>\n",
              "      <td>[('accord', 'NN'), ('gran', 'VBD'), ('company'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>['technopolis', 'plan', 'develop', 'stage', 'a...</td>\n",
              "      <td>[('technopolis', 'NN'), ('plan', 'NN'), ('deve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>['international', 'electronic', 'industry', 'c...</td>\n",
              "      <td>[('international', 'JJ'), ('electronic', 'JJ')...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                 news_tokens_tagged\n",
              "0           0  ...  [('accord', 'NN'), ('gran', 'VBD'), ('company'...\n",
              "1           1  ...  [('technopolis', 'NN'), ('plan', 'NN'), ('deve...\n",
              "2           2  ...  [('international', 'JJ'), ('electronic', 'JJ')...\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TNIyGh0Znhd"
      },
      "source": [
        "No vamos a tener en cuenta las noticias etiquetadas como 'neutrales' ya que el word2vec que vamos a aplicar de \"GoogleNews-vectors-negative300.bin\" no va a aportar para esta categor√≠a y la misma va a generar ruido. Al comienzo relizamos todo el proceso incluyendo las noticias 'neutrales' y el resultado no fue muy bueno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "4_hCqRPo-iJ0",
        "outputId": "05c9ee01-ef7e-414d-e001-2f31bed3dbac"
      },
      "source": [
        "df_sent = df_sent[df_sent.feeling != 'neutral'].reset_index()\n",
        "\n",
        "# Get names of indexes for which column feeling has value 'neutral'\n",
        "# index_neutral_news = df_sent[df_sent['feeling'] == 'neutral'].index\n",
        "# Delete these row indexes from dataFrame\n",
        "# df_sent.drop(index_neutral_news , inplace=True)\n",
        "# df_sent.reset_index(inplace=True)\n",
        "\n",
        "print(df_sent.news.size)\n",
        "df_sent.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>feeling</th>\n",
              "      <th>news</th>\n",
              "      <th>news_tokens</th>\n",
              "      <th>news_tokens_tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>['international', 'electronic', 'industry', 'c...</td>\n",
              "      <td>[('international', 'JJ'), ('electronic', 'JJ')...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>['new', 'production', 'plant', 'company', 'wou...</td>\n",
              "      <td>[('new', 'JJ'), ('production', 'NN'), ('plant'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>['accord', 'company', 'update', 'strategy', 'y...</td>\n",
              "      <td>[('accord', 'NN'), ('company', 'NN'), ('update...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                 news_tokens_tagged\n",
              "0      2  ...  [('international', 'JJ'), ('electronic', 'JJ')...\n",
              "1      3  ...  [('new', 'JJ'), ('production', 'NN'), ('plant'...\n",
              "2      4  ...  [('accord', 'NN'), ('company', 'NN'), ('update...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD5QKrblIy7p"
      },
      "source": [
        "# Descargar el archivo embeddings.zip en:\n",
        "# https://www.kaggle.com/ananyabioinfo/text-classification-using-word2vec/data\n",
        "\n",
        "url = \"../embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryIp2ydTrVT",
        "outputId": "6c5b14a3-0ad4-4ed9-f4c0-681dac05dadf"
      },
      "source": [
        "print(embeddings.most_similar('camera', topn = 5))\n",
        "#print(embeddings.doesnt_match(['apple','banana','flower']))\n",
        "#embeddings.most_similar(positive = ['king','woman'], negative = ['man'])\n",
        "print(\"Cantidad de palabras: \", embeddings.vectors.size)\n",
        "print(\"Tama√±o del vector para cada palabra: \", embeddings.vector_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cameras', 0.8131939172744751), ('Wagging_finger', 0.7311819791793823), ('camera_lens', 0.7250816822052002), ('camcorder', 0.7037474513053894), ('Camera', 0.6848659515380859)]\n",
            "Cantidad de palabras:  900000000\n",
            "Tama√±o del vector para cada palabra:  300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPt6prwPLTOc"
      },
      "source": [
        "Algoritmo para aplicar el embedding a cada palabra de cada documento (que se encuentre dentro de las palabras con las que cuenta), al finalizar de recorrer todas las palabras de un documento se realiza un promedio para dicha noticia, esto para cada documento del corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoJv4T-ELWol",
        "outputId": "6b615043-2011-4109-a82c-2fb0534a2536"
      },
      "source": [
        "docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
        "\n",
        "for doc in df_sent['news_tokens']: # looping through each document\n",
        "    temp = pd.DataFrame() # creating a temporary dataframe\n",
        "    \n",
        "    for word in doc: # looping through each word of a single document\n",
        "        try:\n",
        "            word_vec = embeddings[word] # if word is present in embeddings (goole provides weights associate with words(300)) then proceed\n",
        "            temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    doc_vector = temp.mean() # take the average of each column (w0, w1, w2,........w300)\n",
        "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n",
        "\n",
        "docs_vectors.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1966, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2viLTVwacE-"
      },
      "source": [
        "Se termina realizando para cada documento (noticia) una media con todos los vectores de cada palabra que conforman un documento, y este vector promedio se asigna a dicho documento como si fuera el resultado final, estas 300 variables nos deber√≠an aportar una mayor informaci√≥n para poder deducir el sentimiento de la noticia, m√°s informaci√≥n que lo que nos puede aportar el propio texto.\n",
        "\n",
        "Es por esto que el resultado es una matriz de 1966 documentos x 300 variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vemY5rwHaXmz",
        "outputId": "34cd7cf1-0cc9-41a1-de25-568fe978c042"
      },
      "source": [
        "pd.isnull(docs_vectors).sum().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eibyq08SfeGV"
      },
      "source": [
        "docs_vectors['feeling'] = df_sent['feeling']\n",
        "docs_vectors = docs_vectors.dropna()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwGwXhH8gPnH",
        "outputId": "cc2028f9-3f7d-4f17-ddb6-c0eff34b1b20"
      },
      "source": [
        "print(pd.isnull(docs_vectors).sum().sum())\n",
        "\n",
        "print(docs_vectors.shape)\n",
        "print(\"Positive: \", docs_vectors[docs_vectors.feeling == 'positive'].feeling.size)\n",
        "print(\"Negative: \", docs_vectors[docs_vectors.feeling == 'negative'].feeling.size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(1966, 301)\n",
            "Positive:  1362\n",
            "Negative:  604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WnHTAPQhE2h",
        "outputId": "9cdaceec-b6f7-4ba1-842e-1084040207ef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(docs_vectors.drop('feeling', axis = 1),\n",
        "                                                   docs_vectors['feeling'],\n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state = 42)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1572, 300), (1572,), (394, 300), (394,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jNBj5VTNdAm"
      },
      "source": [
        "A partir de aqu√≠ vamos a aplicar diferentes modelos, recibiendo como entrada los vectores de 300 variables (x) generados aplicando el word2vec, uno por cada noticia, con su respectiva etiqueta de sentimiento (y).\n",
        "\n",
        "Esperamos obtener un modelo que prediga el sentimiento de las noticias de forma m√°s acertada que los que obtuvimos en la entrega anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHbYileL78Hr"
      },
      "source": [
        "##Ada Boost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0hiUQjoiXsk",
        "outputId": "e7071126-1002-443e-a8ee-881497c6ec4f"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model = AdaBoostClassifier(n_estimators = 20)\n",
        "model.fit(X_train, y_train)\n",
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=20, random_state=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7VKxRcljRMi",
        "outputId": "0c66cea7-b3f9-4fbc-d438-d2ac68ae512f"
      },
      "source": [
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "text = \"Ada Boost Classifier - Reporte de clasificaci√≥n del conjunto de testeo\"\n",
        "print(len(text)*\"=\")\n",
        "print(text)\n",
        "print(len(text)*\"=\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Ada Boost Classifier - Reporte de clasificaci√≥n del conjunto de testeo\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.59      0.31      0.40       124\n",
            "    positive       0.74      0.90      0.81       270\n",
            "\n",
            "    accuracy                           0.72       394\n",
            "   macro avg       0.67      0.61      0.61       394\n",
            "weighted avg       0.69      0.72      0.68       394\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXJqK-VY7hUN"
      },
      "source": [
        "##SGDClassifier: SVM & Regresi√≥n Log√≠stica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cj2pFTImecF"
      },
      "source": [
        "Utilizamos SGDClassifier para probar modelos lineales, y GridSearchCV para probar hiperparametros y realizar Cross-Validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqWoPL6CmY0E"
      },
      "source": [
        "param_grid = {\n",
        "    'loss': [\n",
        "        'hinge',    # SVM\n",
        "        'log'       # logistic regression\n",
        "    ],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
        "    'alpha': [0.00001, 0.0001, 0.001, 0.01]\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23ZURIbgmwbG",
        "outputId": "2de1c0e7-e3c8-481c-ba32-760c2e6a614b"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model = SGDClassifier(random_state=0)\n",
        "cv = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "best_model = cv.best_estimator_\n",
        "print(best_model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzXCtsJ9qYzq",
        "outputId": "ac04cf74-a6f9-4ef5-e802-ed87345566f3"
      },
      "source": [
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "text = \"SGD Classifier - Reporte de clasificaci√≥n del conjunto de testeo\"\n",
        "print(len(text)*\"=\")\n",
        "print(text)\n",
        "print(len(text)*\"=\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================\n",
            "SGD Classifier - Reporte de clasificaci√≥n del conjunto de testeo\n",
            "================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.55      0.56      0.56       124\n",
            "    positive       0.80      0.79      0.79       270\n",
            "\n",
            "    accuracy                           0.72       394\n",
            "   macro avg       0.67      0.67      0.67       394\n",
            "weighted avg       0.72      0.72      0.72       394\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "QZRsSfO_oekl",
        "outputId": "123316b6-a12c-4ca4-e2aa-29d6aaa8a0da"
      },
      "source": [
        "results = cv.cv_results_\n",
        "df_result_cv = pd.DataFrame(results)\n",
        "df_result_cv[df_result_cv.rank_test_score<8][['param_loss', 'param_alpha', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_loss</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>log</td>\n",
              "      <td>1e-05</td>\n",
              "      <td>0.563609</td>\n",
              "      <td>0.076831</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hinge</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.592833</td>\n",
              "      <td>0.078960</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hinge</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.585005</td>\n",
              "      <td>0.060471</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>log</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.573773</td>\n",
              "      <td>0.089658</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>log</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.584304</td>\n",
              "      <td>0.073269</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>log</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.573210</td>\n",
              "      <td>0.088846</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>log</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.589710</td>\n",
              "      <td>0.045837</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_loss param_alpha  mean_test_score  std_test_score  rank_test_score\n",
              "7         log       1e-05         0.563609        0.076831                7\n",
              "8       hinge      0.0001         0.592833        0.078960                1\n",
              "11      hinge      0.0001         0.585005        0.060471                3\n",
              "12        log      0.0001         0.573773        0.089658                5\n",
              "13        log      0.0001         0.584304        0.073269                4\n",
              "14        log      0.0001         0.573210        0.088846                6\n",
              "15        log      0.0001         0.589710        0.045837                2"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMiA0vtI8K_J"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sJ5okf28OEh",
        "outputId": "ee665323-3ee0-421d-fd64-244117dae385"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [20, 30, 40, None],\n",
        "    'n_estimators': [20, 30, 40],\n",
        "    }\n",
        "\n",
        "model = RandomForestClassifier(random_state=0)\n",
        "cv = GridSearchCV(model, param_grid, scoring='f1_macro', cv=3, n_jobs=-1)\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "best_model = cv.best_estimator_\n",
        "print(best_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=30, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
            "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
            "                       warm_start=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm2rSU8V9mvy",
        "outputId": "2d07554c-b8bc-4e68-800f-30fab1886308"
      },
      "source": [
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "text = \"Random Forest Classifier - Reporte de clasificaci√≥n del conjunto de testeo\"\n",
        "print(len(text)*\"=\")\n",
        "print(text)\n",
        "print(len(text)*\"=\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================\n",
            "Random Forest Classifier - Reporte de clasificaci√≥n del conjunto de testeo\n",
            "==========================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.59      0.38      0.46       124\n",
            "    positive       0.76      0.88      0.81       270\n",
            "\n",
            "    accuracy                           0.72       394\n",
            "   macro avg       0.68      0.63      0.64       394\n",
            "weighted avg       0.71      0.72      0.70       394\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gSn0zFHYDJn"
      },
      "source": [
        "##Conclusi√≥n\n",
        "\n",
        "De los modelos anteriormente probados el que obtuvo mejor resultados tanto en accuracy como en f1 fue el modelo de SVM, luego cas√≠ con igual desempe√±o Regresi√≥n Logistica, y por debajo Random Forest seguido de Ada Boost Classifier.\n",
        "\n",
        "Los resultados de los modelos que hemos obtenido hasta ahora no son mejores a los obtenidos en el entrega anterior, la entrega 3, en la cual no se aplic√≥ ning√∫n tipo de embedding a los textos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPNgu5ItBUrH"
      },
      "source": [
        "**Enlace de referencia:**\n",
        "\n",
        "https://www.kaggle.com/ananyabioinfo/text-classification-using-word2vec/notebook"
      ]
    }
  ]
}